{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Convolutional Networks for Clickbait Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Stephen Gelinas, Kazuma Yamamoto, Ethan Zhou\\\n",
    "Credits: Parker Erickson https://colab.research.google.com/drive/11tcL4KXXwY__TmUUTjOf6InFQMC-VsG6#scrollTo=_BNqh7fz0486 \\\n",
    "Pytorch Implementation of GCN: https://github.com/iworldtong/text_gcn.pytorch, https://github.com/codeKgu/Text-GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Install Queries on TigerGraph Server - UPDATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook walks through a basic example of using a graph convolutional neural network (GCN) for text classification. The data is collected from a TigerGraph database using a Python package [pyTigerGraph](https://github.com/tigergraph/pyTigerGraph)\n",
    ". Data collected is then pushed through a GCN to output predictions about a headline."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CREATE QUERY userRatings(VERTEX<USER> user) FOR GRAPH Recommender { \n",
    "  /* movieID | userID | userRating | term | termRating */\n",
    "  SumAccum<float> @rating;\n",
    "\n",
    "    src = {user};\n",
    "\n",
    "    S1 = SELECT tgt FROM src:s -(rate:e)-> MOVIE:tgt\n",
    "       ACCUM tgt.@rating += e.rating;\n",
    "\n",
    "  PRINT S1[S1.movie_id as movieID, S1.name as movieTitle, S1.@rating as userRating];\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CREATE QUERY movieLinks() FOR GRAPH Recommender SYNTAX v2{ \n",
    "    TYPEDEF TUPLE <STRING src, STRING dest> TUPLE_RECORD;\n",
    "    ListAccum<TUPLE_RECORD> @@tupleRecords;\n",
    "    movies = {MOVIE.*};  \n",
    "    result = SELECT tgt FROM movies:s-(:e1)-TERM:mid-(:e2)-MOVIE:tgt WHERE s != tgt \n",
    "             ACCUM @@tupleRecords += TUPLE_RECORD (s.name, tgt.name);\n",
    "    PRINT @@tupleRecords;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Installing Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core packages that need to be installed are PyTorch, dgl, and pyTigerGraph. PyTorch and dgl are used for creating and training the GCN, while pyTigerGraph is used for connecting to the TigerGraph database. We also import networkx for converting the list of edges from TigerGraph into a graph dgl can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyTigerGraph\n",
      "  Downloading pyTigerGraph-1.2.5-py3-none-any.whl (170 kB)\n",
      "\u001b[K     |████████████████████████████████| 170 kB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting validators\n",
      "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
      "Requirement already satisfied: requests in /Users/stephengelinas/opt/anaconda3/lib/python3.7/site-packages (from pyTigerGraph) (2.22.0)\n",
      "Collecting pyTigerDriver\n",
      "  Downloading pyTigerDriver-1.0.15-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /Users/stephengelinas/opt/anaconda3/lib/python3.7/site-packages (from validators->pyTigerGraph) (4.4.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/stephengelinas/opt/anaconda3/lib/python3.7/site-packages (from requests->pyTigerGraph) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/stephengelinas/opt/anaconda3/lib/python3.7/site-packages (from requests->pyTigerGraph) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/stephengelinas/opt/anaconda3/lib/python3.7/site-packages (from requests->pyTigerGraph) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/stephengelinas/opt/anaconda3/lib/python3.7/site-packages (from requests->pyTigerGraph) (3.0.4)\n",
      "Building wheels for collected packages: validators\n",
      "  Building wheel for validators (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19567 sha256=869049b08848f8f9de21e8f9420ae9ae76d0391b56db930717bb929224cb7467\n",
      "  Stored in directory: /Users/stephengelinas/Library/Caches/pip/wheels/5f/55/ab/36a76989f7f88d9ca7b1f68da6d94252bb6a8d6ad4f18e04e9\n",
      "Successfully built validators\n",
      "Installing collected packages: validators, pyTigerDriver, pyTigerGraph\n",
      "Successfully installed pyTigerDriver-1.0.15 pyTigerGraph-1.2.5 validators-0.20.0\n",
      "Requirement already satisfied: torch in /Users/stephengelinas/opt/anaconda3/lib/python3.7/site-packages (1.9.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.14.0-cp37-cp37m-macosx_10_9_x86_64.whl (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 213 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /Users/stephengelinas/opt/anaconda3/lib/python3.7/site-packages (from torch) (3.10.0.2)\n",
      "Requirement already satisfied: numpy in /Users/stephengelinas/opt/anaconda3/lib/python3.7/site-packages (from torchvision) (1.19.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/stephengelinas/opt/anaconda3/lib/python3.7/site-packages (from torchvision) (9.0.0)\n",
      "Requirement already satisfied: requests in /Users/stephengelinas/opt/anaconda3/lib/python3.7/site-packages (from torchvision) (2.22.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/stephengelinas/opt/anaconda3/lib/python3.7/site-packages (from requests->torchvision) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/stephengelinas/opt/anaconda3/lib/python3.7/site-packages (from requests->torchvision) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/stephengelinas/opt/anaconda3/lib/python3.7/site-packages (from requests->torchvision) (1.25.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/stephengelinas/opt/anaconda3/lib/python3.7/site-packages (from requests->torchvision) (2.8)\n",
      "\u001b[31mERROR: torchvision 0.14.0 has requirement torch==1.13.0, but you'll have torch 1.9.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.14.0\n",
      "Collecting dgl\n",
      "  Downloading dgl-0.9.1-cp37-cp37m-macosx_10_9_x86_64.whl (3.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.4 MB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting psutil>=5.8.0\n",
      "  Using cached psutil-5.9.4-cp36-abi3-macosx_10_9_x86_64.whl (243 kB)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/stephengelinas/opt/anaconda3/lib/python3.7/site-packages (from dgl) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /Users/stephengelinas/opt/anaconda3/lib/python3.7/site-packages (from dgl) (1.19.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/stephengelinas/opt/anaconda3/lib/python3.7/site-packages (from dgl) (2.22.0)\n",
      "Requirement already satisfied: networkx>=2.1 in /Users/stephengelinas/opt/anaconda3/lib/python3.7/site-packages (from dgl) (2.4)\n",
      "Requirement already satisfied: tqdm in /Users/stephengelinas/opt/anaconda3/lib/python3.7/site-packages (from dgl) (4.62.3)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/stephengelinas/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->dgl) (1.25.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/stephengelinas/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->dgl) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/stephengelinas/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->dgl) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/stephengelinas/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->dgl) (2019.11.28)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/stephengelinas/opt/anaconda3/lib/python3.7/site-packages (from networkx>=2.1->dgl) (4.4.1)\n",
      "\u001b[31mERROR: spyder 4.0.1 requires pyqt5<5.13; python_version >= \"3\", which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: spyder 4.0.1 requires pyqtwebengine<5.13; python_version >= \"3\", which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\u001b[0m\n",
      "Installing collected packages: psutil, dgl\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.6.7\n",
      "    Uninstalling psutil-5.6.7:\n",
      "      Successfully uninstalled psutil-5.6.7\n",
      "Successfully installed dgl-0.9.1 psutil-5.9.4\n",
      "Requirement already satisfied: networkx in /Users/stephengelinas/opt/anaconda3/lib/python3.7/site-packages (2.4)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/stephengelinas/opt/anaconda3/lib/python3.7/site-packages (from networkx) (4.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyTigerGraph\n",
    "!pip install torch torchvision\n",
    "!pip install dgl\n",
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Installing Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now import the packages we just installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pyTigerGraph as tg\n",
    "import dgl\n",
    "import networkx as nx\n",
    "from heapq import nlargest, nsmallest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define some variables, such as the number of epochs of training (usually only need 30 or less for a 2-layer GCN), the learning rate (0.01 seems to work well). (optimize this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpochs = 25\n",
    "learningRate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Creating the Graph Convolutional Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The block below defines some functions and classes for the GCN. The main ones to look at are the GCNLayer, which are the individual building blocks that the GCN class is made out of. The GCN class defines the structure of our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, dropout_rate=0., num_classes=10):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 200)\n",
    "        self.fc2 = nn.Linear(200, num_classes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, input_dim, \\\n",
    "                       output_dim, \\\n",
    "                       support, \\\n",
    "                       act_func = None, \\\n",
    "                       featureless = False, \\\n",
    "                       dropout_rate = 0., \\\n",
    "                       bias=False):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.support = support\n",
    "        self.featureless = featureless\n",
    "        for i in range(len(self.support)):\n",
    "            setattr(self, 'W{}'.format(i), nn.Parameter(torch.randn(input_dim, output_dim)))\n",
    "        if bias:\n",
    "            self.b = nn.Parameter(torch.zeros(1, output_dim))\n",
    "        self.act_func = act_func\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        for i in range(len(self.support)):\n",
    "            if self.featureless:\n",
    "                pre_sup = getattr(self, 'W{}'.format(i))\n",
    "            else:\n",
    "                pre_sup = x.mm(getattr(self, 'W{}'.format(i)))\n",
    "            if i == 0:\n",
    "                out = self.support[i].mm(pre_sup)\n",
    "            else:\n",
    "                out += self.support[i].mm(pre_sup)\n",
    "        if self.act_func is not None:\n",
    "            out = self.act_func(out)\n",
    "        self.embedding = out\n",
    "        return out\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, \\\n",
    "                       support,\\\n",
    "                       dropout_rate=0., \\\n",
    "                       num_classes=10):\n",
    "        super(GCN, self).__init__()\n",
    "        # GraphConvolution\n",
    "        self.layer1 = GraphConvolution(input_dim, 200, support, act_func=nn.ReLU(), featureless=True, dropout_rate=dropout_rate)\n",
    "        self.layer2 = GraphConvolution(200, num_classes, support, dropout_rate=dropout_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Creating Database Connection and Creating Edge List - UPDATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section instantiates a connection to the TigerGraph database and creates a list of tuples which consist of directed edges in the form of (from, to). This is done through two dictionaries that corresponds an article name to a unique numerical id that is needed to process the graph in the GCN.\n",
    "\n",
    "\n",
    "#### **Assumption Alert:** We oversimplify the graph here. The query returns pairs of movies that share the same term (genre). In the real world, most people like a variety of genres and therefore their views are a little more nuanced than creating a graph where the edges are created if the movies share the same genre. This hurts accuracy (a lot). Better link creation factors might be actors, directors, etc. but we don't have that in this dataset. Where TigerGraph comes in is the ease of data extraction, as there are no JOIN operations to create these links between movies.\n",
    "* Note: It is possible to create a GCN that has multiple types of verticies, (known as a Relational Graph Convolutional Notebook) but it is more complex. A good way to get started is to simplify until you only have relations between the same type of thing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tg.TigerGraphConnection(\n",
    "    ipAddress=\"https://graphml.i.tgcloud.io\", \n",
    "    graphname=\"Recommender\", \n",
    "    apiToken=\"bekr9ls24mlh4kbkd7g28stq8vpj67vi\") # Really not the best idea to have your API key out in the open, but for the sake of the demo, here it is\n",
    "\n",
    "movieToNum = {} # translation dictionary for movie name to number (for dgl)\n",
    "numToMovie = {} # translation dictionary for number to movie name\n",
    "i = 0\n",
    "def createEdgeList(result): # returns tuple of number version of edge\n",
    "    global i\n",
    "    if result[\"src\"] in movieToNum:\n",
    "        fromKey = movieToNum[result[\"src\"]]\n",
    "    else:\n",
    "        movieToNum[result[\"src\"]] = i\n",
    "        numToMovie[i] = result[\"src\"]\n",
    "        fromKey = i\n",
    "        i+=1\n",
    "    if result[\"dest\"] in movieToNum:\n",
    "        toKey = movieToNum[result[\"dest\"]]\n",
    "    else:\n",
    "        movieToNum[result[\"dest\"]] = i\n",
    "        numToMovie[i] = result[\"dest\"]\n",
    "        toKey = i\n",
    "        i+=1\n",
    "    return (fromKey, toKey)\n",
    "    \n",
    "edges = [createEdgeList(thing) for thing in graph.runInstalledQuery(\"movieLinks\", {}, sizeLimit=128000000)[\"results\"][0][\"@@tupleRecords\"]] # creates list of edges\n",
    "print(len(edges))\n",
    "print(edges[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Initializing Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section converts the list of edges into a graph that DGL can process in the GCN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.Graph()\n",
    "g.add_edges_from(edges)\n",
    "\n",
    "\n",
    "G = dgl.DGLGraph(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Adding Features to Graph - UPDATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We one-hot encode the features of the verticies in the graph. Feature assignment can be done a multitude of different ways, this is just the fastest and easiest, especially given the lack of attributal information in the dataset.\n",
    "\n",
    "If you had a graph of documents for example, you could run doc2vec on those documents to create a feature vector and create the feature matrix by concatenating those together.\n",
    "\n",
    "Another possiblity is that you have a graph of songs, artists, albums, etc. and you could use tempo, max volume, minimum volume, length, and other numerical descriptions of the song to create the feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.ndata[\"feat\"] = torch.eye(G.number_of_nodes())\n",
    "\n",
    "print(G.nodes[2].data['feat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Get User Data - UPDATE OR MAYBE DELETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we get a specific user's movie preferences. There is a lot of list comprehension going on, but just know that we are getting the user's 3 highest and lowest reviewed movies for a total of 6 labelled datapoints to feed the GCN. The remainder of the user's data is then processed and saved to test the accuracy of the GCN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = graph.runInstalledQuery(\"userRatings\", {\"user\":\"217\"})[\"results\"][0][\"S1\"]\n",
    "print(\"Total Number of Reviews by User: \"+str(len(ratings)))\n",
    "top3Movies = [thing[\"attributes\"][\"movieTitle\"] for thing in nlargest(3, ratings, key=lambda item: item[\"attributes\"][\"userRating\"])] # getting the 3 highest rated movies by the user\n",
    "bottom3Movies = [thing[\"attributes\"][\"movieTitle\"] for thing in nsmallest(3, ratings, key=lambda item: item[\"attributes\"][\"userRating\"])] # getting the 3 lowest rated movies by the user\n",
    "unclassifiedMovies = [thing for thing in ratings if not((thing[\"attributes\"][\"movieTitle\"] in top3Movies) or (thing[\"attributes\"][\"movieTitle\"] in bottom3Movies))]\n",
    "\n",
    "def filterNegative(thing):\n",
    "    if thing[\"attributes\"][\"userRating\"] < 0:\n",
    "        return thing\n",
    "\n",
    "negativeRating = [filterNegative(thing)[\"attributes\"][\"movieTitle\"] for thing in unclassifiedMovies if filterNegative(thing) != None]\n",
    "positiveRating = [thing[\"attributes\"][\"movieTitle\"] for thing in ratings if thing[\"attributes\"][\"movieTitle\"] not in negativeRating]\n",
    "print(\"Number of movies whose rating is unknown to the GCN: \"+str(len(unclassifiedMovies)))\n",
    "print(\"Number of unknown movies with a negative rating: \"+str(len(negativeRating)))\n",
    "print(\"Number of unknown movies with a positive rating: \"+str(len(positiveRating)))\n",
    "print(top3Movies)\n",
    "print(bottom3Movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Creating Neural Network and Labelling Relevant Verticies - UPDATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we create the GCN. A two-layered GCN appears to work better than deeper networks, and this is further corroborated by the fact [this](https://arxiv.org/abs/1609.02907) paper only used a two-layered one. We also label the wanted and unwanted verticies and setup the optimizer. Since the GCN is a semi-supervised algorithm, we do not label all of the nodes to their correct classes before training - only two are needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GCN(G.number_of_nodes(), 15, 2) #Two layer GCN\n",
    "inputs = G.ndata[\"feat\"]\n",
    "labeled_nodes = torch.tensor([movieToNum[top3Movies[0]], movieToNum[top3Movies[1]], movieToNum[top3Movies[2]], \n",
    "                              movieToNum[bottom3Movies[0]], movieToNum[bottom3Movies[1]], movieToNum[bottom3Movies[2]]])  # only the liked movies and the disliked movies are labelled\n",
    "labels = torch.tensor([0, 0, 0, 1, 1, 1])  # their labels are different\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learningRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the training loop that trains the GCN. Unlike many traditional deep learning architectures, GCNs don't always need that much training or as large of data sets due to their exploitation of the *structure* of the data, as opposed to only the features of the data.\n",
    "* Note: due to the randomized initial values of the weights in the neural network, sometimes models don't work very well, or their loss gets stuck at a relatively large number (Try and be below a loss of about .7 at minimum). If that happens, just stop and restart the training process (also rerun the cell above to reset the weights) and hope for better luck! Alternatively, you can run more epochs in hopes of eventually getting out of the rut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logits = []\n",
    "for epoch in range(numEpochs):\n",
    "    logits = net(G, inputs)\n",
    "    # we save the logits for visualization later\n",
    "    all_logits.append(logits.detach())\n",
    "    logp = F.log_softmax(logits, 1)\n",
    "    # we only compute loss for labeled nodes\n",
    "    loss = F.nll_loss(logp[labeled_nodes], labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch %d | Loss: %6.3e' % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Testing Accuracy - UPDATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code that processes the GCN's results and calculates the accuracy based off the verticies that the user has reviewed, but were not labelled in the graph for the GCN to use. While this accuracy is pretty mediocre, the GCN does make predictions based off of movies sharing the same genre, and therefore with better data, there could be (and almost certainly would be) an improvement in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(all_logits[numEpochs-1])\n",
    "\n",
    "positivePrediction = []\n",
    "negativePrediction = []\n",
    "a = 0\n",
    "for movie in predictions:\n",
    "    if movie[0] >= movie[1]:\n",
    "        positivePrediction.append(numToMovie[a])\n",
    "    else:\n",
    "        negativePrediction.append(numToMovie[a])\n",
    "    a+=1\n",
    "\n",
    "totalPredictions = len(unclassifiedMovies)\n",
    "totalRight = 0\n",
    "\n",
    "for movie in unclassifiedMovies:\n",
    "    if (movie[\"attributes\"][\"movieTitle\"] in negativePrediction) and (movie[\"attributes\"][\"movieTitle\"] in negativeRating):\n",
    "        totalRight += 1\n",
    "    if (movie[\"attributes\"][\"movieTitle\"] in positivePrediction) and (movie[\"attributes\"][\"movieTitle\"] in positiveRating):\n",
    "        totalRight += 1\n",
    "    \n",
    "print(\"Number of movies whose rating is unknown to the GCN: \"+str(len(unclassifiedMovies)))\n",
    "print(\"Total number of correct classifications: \"+str(totalRight))\n",
    "print(\"Accuracy: \"+str(totalRight/totalPredictions))\n",
    "print(\"Some movies that the user might like (In no particular order): \"+str(positiveRating[:10]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "c0f44f62e573cea88b6a9cab083f0e4138e145194b4edc39d4088f7de387635d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
